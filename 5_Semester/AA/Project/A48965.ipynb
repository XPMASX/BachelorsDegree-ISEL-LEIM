{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03549355",
   "metadata": {},
   "source": [
    "$$\\large{\\mathbf{Instituto\\ Superior\\ de\\ Engenharia\\ de\\ Lisboa}}$$\n",
    "\n",
    "$$\\large{\\mathrm{Licenciatura\\ em\\ Engenharia\\ Informática\\ e\\ Multimédia}}$$\n",
    "\n",
    "$$\\Large{\\mathbf{Aprendizagem \\ Automatica}}$$\n",
    "\n",
    "$$\\normalsize{\\mathbf{Trabalho \\ Laboratorial-\\ Rate \\ Beer \\ Dataset}}$$\n",
    "\n",
    "$$\\normalsize{\\mathbf{Pedro\\ Silva\\ (48965)\\\\}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d115e7",
   "metadata": {},
   "source": [
    "<a id='section0'></a>\n",
    "# Índice\n",
    "<hr style=\"height:3px\"/>\n",
    "\n",
    "1. [Introdução](#section1)\n",
    "2. [Construção do vocabulário](#section2)\n",
    "    1. [Inicialização](#section2.1)\n",
    "    2. [Modelo Bag of Words (BoW)](#section2.2)\n",
    "3. [Classificação Binária](#section3)\n",
    "    1. [Treino](#section3.1)\n",
    "    2. [Teste](#section3.2)\n",
    "4. [Classificação Multi-Classe](#section4)\n",
    "    1. [Treino](#section4.1)\n",
    "    2. [Teste](#section4.2)\n",
    "5. [PCA](#section5)\n",
    "6. [Conclusões](#section6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7f241",
   "metadata": {},
   "source": [
    "# 1. Introdução <a id='section1'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "Em termos globais, o que se pretende e determinar a qualidade de uma cerveja baseado no que foi escrito sobre a mesma. Neste contexto surgem duas tarefas de classificação a ser implementadas:\n",
    "\n",
    "## Classificação Binária:\n",
    "Nesta tarefa, pretende-se saber se o crítico considera a cerveja muito boa ou muito má, baseado no que escreveu. Considere que uma cerveja e considerada muito boa quando obteve uma pontuação global (campo overall) de 9 ou mais valores. Considere ainda que uma cerveja e considerada muito má quando obteve uma pontuação global de 2 ou menos valores.\n",
    "\n",
    "## Classificação Multi-Classe: \n",
    "Prever a pontuação de três aspetos das críticas (smell, taste e overall). Neste ponto,\n",
    "treine e avalie os classificadores com os dados de treino e verifique se as estimativas do\n",
    "desempenho condizem com os resultados obtidos no conjunto de teste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6a58",
   "metadata": {},
   "source": [
    "# 2. Construção do vocabulário <a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c749b6f",
   "metadata": {},
   "source": [
    "## 2.1. Inicialização <a id='section2.1'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "\n",
    "Vamos realizar os imports e inicializar os dados que vamos utilizar neste caso o ficheiro: 'rateBeer75Ktrain.p'. Vamos extrair também o valor da review ao tirar o valor antes da '/'. Criamos também uma função para converter uma string em tfidf dado um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import strip_accents_ascii\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Carregar os dados\n",
    "dados_treino = pickle.load(open('rateBeer75Ktrain.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e rótulos (classificações gerais)\n",
    "avaliacoes = [dados_treino[chave]['review'] for chave in dados_treino]\n",
    "\n",
    "# Extrair a parte numérica antes de '/' do campo 'overall'\n",
    "overall = [int(re.search(r'\\d+', dados_treino[chave]['overall']).group()) for chave in dados_treino]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(avaliacoes, overall, test_size=0.4, random_state=42)\n",
    "\n",
    "# Função para converter uma string de texto ou lista de strings na representação TF-IDF\n",
    "def converte_texto_para_tfidf(modelo, texto):\n",
    "    # Se o texto for uma lista de strings, junte as strings em um único texto\n",
    "    if isinstance(texto, list):\n",
    "        texto = ' '.join(texto)\n",
    "    \n",
    "    # Use o transform para converter o texto em representação TF-IDF\n",
    "    representacao_tfidf = modelo.named_steps['tfidf'].transform([texto])\n",
    "    \n",
    "    return representacao_tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae37e",
   "metadata": {},
   "source": [
    "## 2.2. Modelo Bag of Words (BoW)<a id='section2.2'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "\n",
    "Uma das formas de representar texto é o modelo “Bag of Words” (i.e. saco de palavras). Nesta representação a forma, estrutura do texto é descartada bem como a ordem das palavras e é só tido em conta o número de ocorrências de cada palavra em cada documento do corpus. O resultado final é uma matriz denominada “documento-termo” (do inglês _document-term matrix_) com dimensão Nxd, onde N é número de documentos no corpus e d é o número de palavras do vocabulário. BoW é uma técnica não supervisionada de representar um texto por um vetor numérico.\n",
    "\n",
    "A representação BoW consiste nos seguintes passos:\n",
    "\n",
    "1. **Tokenization**\n",
    "   Este processo consiste em dividir cada documento em palavras (ou _tokens_), por exemplo separando as palavras nos textos através dos caracteres de espaço ou pontuação.\n",
    "2. **Construção do Vocabulário:**\n",
    "   Construir um vocabulário constituído por todas ou por um sub-conjunto das palavras presentes no corpus.\n",
    "3. **Codificação:**\n",
    "   - Contar o número de vezes que cada palavra do vocabulário aparece em cada documento.\n",
    "   - Representar cada documento por um vetor de d dimensões, uma por cada palavra no vocabulário, com valores proporcionais ao número de ocorrências dessa palavra no documento. (Nota: estes vetores terão a maior parte dos seus coeficientes a zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed8776",
   "metadata": {},
   "source": [
    "## Questões Práticas:\n",
    "\n",
    "1. Cada texto é representado por um vetor de dimensão igual ao número de palavras no vocabulário.\n",
    "\n",
    "2. Devido à diversidade de termos, palavras, interjeições, etc., presentes na maioria dos idiomas, se não houver nenhum pré-processamento dos textos, o vocabulário pode ter vários milhares de palavras.\n",
    "\n",
    "3. É por isso aconselhável, antes de fazer a representação BoW, processar os documentos da base de dados de forma a reduzir a dimensão do vocabulário. Existem várias técnicas, tais como considerar só palavras que tenham um número de ocorrências superior a um dado limiar, converter palavras semelhantes numa única palavra, etc.\n",
    "\n",
    "4. O processo de limpeza tem que ser o mesmo para todos os documentos (documentos de treino e de teste, e outros documentos nunca classificados), e deve ser aplicado antes de obter a representação BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110ad67",
   "metadata": {},
   "source": [
    "## Limpeza do texto\n",
    "\n",
    "Existem muitos caracteres ou sequências de caracteres, como mudanças de linha em HTML `<br />`, que não contribuem para discriminar entre boas e más críticas, mas podem prejudicar bastante o desempenho dos classificadores. Existem alguns comandos simples que ajudam a limpar o vocabulário.\n",
    "\n",
    "As classes CountVectorizer e TfidfVectorizer também realizam uma limpeza dos dados. Essas classes extraem apenas palavras com comprimento maior que dois caracteres e convertem os caracteres alfabéticos para minúsculas.\n",
    "\n",
    "Além disso, existe a possibilidade de extrair apenas as palavras que aparecem em mais do que um número pré-definido de documentos usando o parâmetro `min_df` (frequência mínima do documento). Por exemplo, o seguinte comando extrai apenas palavras que aparecem em 5 ou mais documentos:\n",
    "\n",
    "Além disso, é possível especificar qual expressão regular é usada no processo de tokenização. Por padrão, a expressão regular é `r\"\\b\\w\\w+\\b\"`. Isso significa que serão extraídas sequências de caracteres compostas por 2 ou mais letras ou números (`\\w`) e que estão separadas por caracteres de pontuação ou espaços (`\\b`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f05881",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "\n",
    "Outra maneira de reduzir o tamanho do vocabulário é eliminar palavras através de uma lista de \"stop words\". Stop words são palavras que ocorrem frequentemente em uma dada língua (cada idioma tem seu conjunto específico de stop words). O scikit-learn contém uma lista de stop words em inglês no módulo `feature_extraction.text`.\n",
    "\n",
    "A remoção das stop words não tem uma contribuição significativa para o melhoramento da caracterização dos documentos. Pode-se treinar modelos com vocabulários com e sem stop words e verificar se há melhoria no desempenho. Em certas situações, como é o caso de n-gramas, a remoção pode até ser prejudicial. Existem outros métodos mais eficazes para reduzir a dimensão do vocabulário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f0c47",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Essa técnica consiste no processo de transformar uma palavra em sua raiz, o que permite mapear palavras semelhantes em uma única palavra. Por exemplo, palavras como \"studies\", \"studying\", \"studied\" seriam mapeadas para \"studi\".\n",
    "\n",
    "O primeiro algoritmo de stemming foi desenvolvido por Martin F. Porter e ficou conhecido como Porter Stemmer. Este algoritmo está disponível no módulo Natural Language Toolkit (nltk) em Python, juntamente com outros algoritmos de stemming, como os casos do Snowball e Lancaster stemmers.\n",
    "\n",
    "O processo de stemming não leva em consideração o significado das palavras, apenas seu formato. \n",
    "\n",
    "Em resumo, o stemming é uma técnica de pré-processamento que ajuda a simplificar palavras em um texto, removendo variações gramaticais, para facilitar o processamento e a análise de texto em tarefas de PLN, como classificação de texto, agrupamento, recuperação de informações, entre outras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b537b",
   "metadata": {},
   "source": [
    "## Repesentação tf-idf\n",
    "\n",
    "O método TF-IDF (Term Frequency-Inverse Document Frequency) é uma técnica amplamente utilizada na análise de texto. Ele atribui importância às palavras com base em quão frequentemente elas aparecem em poucos documentos, associando a essas palavras um valor mais elevado. É uma técnica não supervisionada que não considera diretamente se as palavras são positivas ou negativas. É importante destacar que a conversão de textos para a representação TF-IDF deve ser realizada após a limpeza dos documentos.\n",
    "\n",
    "O TF-IDF é uma ferramenta valiosa na análise de texto, permitindo identificar as palavras mais importantes em um conjunto de documentos. No contexto da análise de sentimentos em críticas de filmes, por exemplo, o TF-IDF pode ajudar a identificar palavras-chave que são frequentemente associadas a tópicos específicos, mesmo que não estejam diretamente ligadas a críticas positivas ou negativas. Isso pode ser útil para extrair informações relevantes e insights dos documentos de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33045ab3",
   "metadata": {},
   "source": [
    "## N-gramas\n",
    "\n",
    "Uma das limitações da representação BoW (Bag of Words) é que ela descarta informações sobre a ordem das palavras. Frases como \"não é bom, é mau\" e \"não é mau, é bom\" têm a mesma representação, apesar de terem significados opostos. Uma maneira de capturar parte da informação contextual é incluir sequências de duas ou mais palavras que aparecem frequentemente nos documentos na representação BoW. Conjuntos de duas palavras são chamados de bi-gramas, de três palavras são tri-gramas e, em geral, sequências de várias palavras são denominadas n-gramas.\n",
    "\n",
    "É importante notar que a inclusão de n-gramas pode resultar em um aumento significativo no número de entradas no vocabulário. Em teoria, o número máximo de bi-gramas é igual ao número de palavras individuais no vocabulário elevado ao quadrado, o número máximo de tri-gramas é igual ao número de palavras individuais no vocabulário elevado ao cubo e assim por diante. No entanto, devido à estrutura e características da linguagem escrita, o número de n-gramas é substancialmente menor do que o número máximo teórico, mas ainda assim pode ser muito elevado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de tokenização personalizada para excluir palavras com números\n",
    "def custom_tokenizer(text):\n",
    "    tokens = re.findall(r'\\b\\w\\w\\w+\\b', strip_accents_ascii(text.lower()))\n",
    "    # Excluir palavras com números\n",
    "    filtered_tokens = [token for token in tokens if not any(char.isdigit() for char in token)]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2079454",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Registrar o tempo de início\n",
    "tempo_inicio = time.time()\n",
    "\n",
    "# Construir um pipeline com vetorização TF-IDF, Regressão Logística com regularização Ridge, stop words, stemming e n-grams\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        tokenizer=custom_tokenizer,  # Usar o tokenizador personalizado\n",
    "        ngram_range=(1, 4),\n",
    "        min_df=5\n",
    "    )),\n",
    "    ('clf', LogisticRegression(penalty='l2', solver='saga', max_iter=1000, C=1, tol=1e-3))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "text_clf.fit(X_treino, y_treino)\n",
    "\n",
    "# Aceder aos nomes das características do TfidfVectorizer\n",
    "feature_names = text_clf.named_steps['tfidf'].get_feature_names()\n",
    "\n",
    "# Aceder aos coeficientes do modelo de Regressão Logística\n",
    "coeficientes = text_clf.named_steps['clf'].coef_[0]\n",
    "\n",
    "# Criar um dicionário com nomes de recursos e seus coeficientes correspondentes\n",
    "coef_dict = dict(zip(feature_names, coeficientes))\n",
    "\n",
    "# Classificar o dicionário por coeficientes em ordem ascendente (menos importante primeiro)\n",
    "palavras_menos_importantes = sorted(coef_dict.items(), key=lambda x: x[1])[:10]\n",
    "\n",
    "# Classificar o dicionário por coeficientes em ordem descendente (mais importante primeiro)\n",
    "palavras_mais_importantes = sorted(coef_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(\"\\nPalavras Mais Positivas:\")\n",
    "for palavra, coef in palavras_menos_importantes:\n",
    "    print(f\"{palavra}: {coef}\")\n",
    "\n",
    "print(\"\\nPalavras Mais Negativas:\")\n",
    "for palavra, coef in palavras_mais_importantes:\n",
    "    print(f\"{palavra}: {coef}\")\n",
    "\n",
    "# Registrar o tempo de término\n",
    "tempo_fim = time.time()\n",
    "\n",
    "# Calcular o tempo decorrido\n",
    "tempo_decorrido = tempo_fim - tempo_inicio\n",
    "\n",
    "# Imprimir o tempo decorrido em segundos\n",
    "print(f\"\\nTempo decorrido: {tempo_decorrido:.2f} segundos\")\n",
    "\n",
    "\n",
    "#print(\"Vocabulário (Nomes das Features):\", feature_names)\n",
    "#print(\"Tamanho do Vocabulário (Nomes das Features):\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7705dac",
   "metadata": {},
   "source": [
    "Em cima podemos observar as palavras que mais contribuem para uma dada review ter ou não uma boa review. As palavras mais positivas são como é obvio adjetivos e sabores que costumamos considerar agradáveis (como chocolate, uva ou caramelo). O contrário dá-se nas palavras negativas como a cerveja ser considerada aguada, metálica ou de cartão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da137f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever rótulos para o conjunto de teste\n",
    "y_pred = text_clf.predict(X_teste)\n",
    "\n",
    "# Calcular e imprimir a precisão\n",
    "precisao = accuracy_score(y_teste, y_pred)\n",
    "print(f\"Precisão: {precisao:.2f}\")\n",
    "\n",
    "# Imprimir a matriz de confusão\n",
    "matriz_confusao = confusion_matrix(y_teste, y_pred)\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(matriz_confusao)\n",
    "\n",
    "# Imprimir o relatório de classificação\n",
    "relatorio_classificacao = classification_report(y_teste, y_pred)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(relatorio_classificacao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e63d7c",
   "metadata": {},
   "source": [
    "O máximo de precisão que conseguimos foi 29%, quer nós aumentássemos o número de amostras, o número do n-grams ou mudássemos o discriminante logístico por isso conseguimos otimizar a duração do processo a menos de 1 minuto. Acabámos por escolher o Ridge pois este era o que nos dava melhores valores de precisão nas reviews muito boas (score>=9) e muito más (score<=2), ambos os overalls 1 e 10, o min e o max, com 50% o que é o nosso melhor valor. Mudámos também a expressão regular para retirar todas as palavras com menos de 3 letras. Os docentes avisaram que não obter resultados decentes nesta fase é normal por isso não parece existir problema com a nossa abordagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f24bc",
   "metadata": {},
   "source": [
    "# 3. Classificação Binária <a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7071b",
   "metadata": {},
   "source": [
    "Nesta tarefa, pretende-se saber se o crítico considera a cerveja muito boa ou muito má, baseado no que escreveu. Considere que uma cerveja e considerada muito boa quando obteve uma pontuação global (campo overall) de 9 ou mais valores. Considere ainda que uma cerveja e considerada muito má quando obteve uma pontuação global de 2 ou menos valores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980aa79",
   "metadata": {},
   "source": [
    "## 3.1. Treino<a id='section3.1'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "\n",
    "Vamos começar por dividir o conjunto de treino nas reviews muito boas e muito más e descartar as restantes. Vamos usar os mesmos parâmetros que utilizámos na fase anterior mas desta vez utilizamos também o classificador Naive Bayes. O seu princípio básico envolve a aplicação do Teorema de Bayes, assumindo independência condicional entre as características, daí o termo \"Naive\". É notório pela sua eficácia em problemas de classificação, especialmente em tarefas relacionadas com texto, como análise de sentimentos o que é exatamente o que procuramos neste contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a56af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Carregar dados do ficheiro pickle\n",
    "dados_treino = pickle.load(open('rateBeer75Ktrain.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e rótulos (classificações gerais)\n",
    "avaliacoes = [dados_treino[key]['review'] for key in dados_treino]\n",
    "overalls = [int(re.search(r'\\d+', dados_treino[key]['overall']).group()) for key in dados_treino]\n",
    "\n",
    "\n",
    "# Criar rótulos binários para classificação binária (muito bom ou muito mau)\n",
    "overall_binarias = [1 if overall >= 9 else 0 if overall <= 2 else None for overall in overalls]\n",
    "\n",
    "\n",
    "# Remover entradas com None nos rótulos binários\n",
    "dados = list(zip(avaliacoes, overall_binarias))\n",
    "dados = [(avaliacao, overall) for avaliacao, overall in dados if overall is not None]\n",
    "avaliacoes, overall_binarias = zip(*dados)\n",
    "\n",
    "# Construir pipelines para ambos os classificadores (Regressão Logística e Naive Bayes)\n",
    "regressao_logistica_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        tokenizer=custom_tokenizer,\n",
    "        ngram_range=(1, 4),\n",
    "        min_df=5\n",
    "    )),\n",
    "    ('clf', LogisticRegression(penalty='l2', solver='saga', max_iter=1000, C=1, tol=1e-3))\n",
    "])\n",
    "\n",
    "naive_bayes_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        tokenizer=custom_tokenizer,\n",
    "        ngram_range=(1, 4),\n",
    "        min_df=5\n",
    "    )),\n",
    "    ('clf', MultinomialNB())  # Usar Naive Bayes Multinomial\n",
    "])\n",
    "\n",
    "# Lista de classificadores e seus nomes\n",
    "classificadores = [\n",
    "    ('Regressão Logística', regressao_logistica_clf),\n",
    "    ('Naive Bayes', naive_bayes_clf)\n",
    "]\n",
    "\n",
    "# Comparar o desempenho de ambos os classificadores\n",
    "for nome_cls, cls in classificadores:\n",
    "    print(f\"\\n*** {nome_cls} ***\")\n",
    "    \n",
    "    # Dividir dados em conjuntos de treino e teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(avaliacoes, overall_binarias, test_size=0.6, random_state=42)\n",
    "\n",
    "    # Treinar o modelo\n",
    "    cls.fit(X_treino, y_treino)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_predito = cls.predict(X_teste)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    precisao = accuracy_score(y_teste, y_predito)\n",
    "    print(f\"Precisão: {precisao:.2f}\")\n",
    "\n",
    "    # Relatório de Classificação\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_teste, y_predito))\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    print(\"\\nMatriz de Confusão:\")\n",
    "    print(confusion_matrix(y_teste, y_predito))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca24d6e",
   "metadata": {},
   "source": [
    "Como podemos ver pelos resultados em cima ambos os modelos dão nos bastante confiança tendo resultados de 90%. Não foi preciso modicar nada na pipeline apenas mudou o conjunto de teste. Com estas observações podemos usar ambos estes classificadores com todas as certezas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63552bc1",
   "metadata": {},
   "source": [
    "## 3.2. Teste<a id='section3.2'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "Agora que temos os nossos classificadores escolhidos podemos partir para a fase de teste. Nesta fase vamos usar o ficheiro 'rateBeer25Ktest.p' que é próprio para testes. Começamos por mais uma vez extrair apenas as reviews muito más e muito boas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados do ficheiro pickle\n",
    "dados_teste = pickle.load(open('rateBeer25Ktest.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e overall dos dados de teste\n",
    "avaliacoes_teste = [dados_teste[chave]['review'] for chave in dados_teste]\n",
    "overalls = [int(re.search(r'\\d+', dados_teste[chave]['overall']).group()) for chave in dados_teste]\n",
    "\n",
    "# Criar rótulos binários para classificação binária (muito bom ou muito mau)\n",
    "overall_binarios = [1 if overall >= 9 else 0 if overall <= 2 else None for overall in overalls]\n",
    "\n",
    "# Remover entradas com None nos rótulos binários\n",
    "dados = list(zip(avaliacoes_teste, overall_binarios, overalls))\n",
    "dados_filtrados = [(avaliacao, rotulo, pontuacao_real) for avaliacao, rotulo, pontuacao_real in dados if rotulo is not None]\n",
    "avaliacoes_filtradas, overall_binarios_filtrados, overall_filtrado = zip(*dados_filtrados)\n",
    "\n",
    "print(f\"Tamanho do grupo de teste: {len(overall_binarios_filtrados)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16080226",
   "metadata": {},
   "source": [
    "Vamos então testar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46652f1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Definir classificadores\n",
    "classificadores = [\n",
    "    ('Regressão Logística', regressao_logistica_clf),\n",
    "    ('Naive Bayes', naive_bayes_clf)\n",
    "]\n",
    "\n",
    "# Testar cada classificador\n",
    "for nome_clf, clf in classificadores:\n",
    "    print(f\"\\n*** {nome_clf} ***\")\n",
    "\n",
    "    # Prever sentimentos para os dados de teste filtrados\n",
    "    previstos = clf.predict(avaliacoes_filtradas)\n",
    "\n",
    "    # Converter rótulos previstos em sentimentos legíveis\n",
    "    pontuacoes_previstas = [\"Muito Bom\" if pred == 1 else \"Muito Mau\" for pred in previstos]\n",
    "\n",
    "    # Avaliar o desempenho do modelo nos dados de teste filtrados\n",
    "    precisao = accuracy_score(overall_binarios_filtrados, previstos)\n",
    "    print(f\"Precisão: {precisao:.2f}\")\n",
    "\n",
    "    # Métricas adicionais de avaliação\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(overall_binarios_filtrados, previstos))\n",
    "\n",
    "    print(\"\\nMatriz de Confusão:\")\n",
    "    print(confusion_matrix(overall_binarios_filtrados, previstos))\n",
    "\n",
    "    # Imprimir o sentimento previsto, pontuação geral real e rótulo binário real para cada avaliação nos dados de teste filtrados\n",
    "    #for i, (sentimento, pontuacao_real) in enumerate(zip(pontuacoes_previstas, overall_filtrado)):\n",
    "    #    print(f\"Avaliação {i + 1}: Sentimento Previsto - {sentimento}, Pontuação Real - {pontuacao_real}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec493d",
   "metadata": {},
   "source": [
    "Como é lógico os resultados são inferiores aos anteriores mas isto não é por muito sendo a maior queda de 3% no classificador Naive Bayes. Com estes testes gerais conseguimos chegar à conclusão que ambos os classificadores estão a funcionar bastante bem mas vamos aprofundar um pouco a questão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce156e",
   "metadata": {},
   "source": [
    "Vamos fazer um pequeno teste numa review fabricada por nós onde vamos utilizar 2 adjetivos negativos e 1 positivo, logo o resultado esperado vai ser uma muito má. Vamos fazer o mesmo para uma muito boa. Acrescentamos também uma média só para testar e observar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af708b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar reviews\n",
    "review_teste_ma = \"This beer is bad! The flavor sucks but the aroma is nice.\"\n",
    "review_teste_mid = \"This beer is alright. The flavor is not good but the aroma smells like caramel.\"\n",
    "review_teste_boa = \"This beer is great! The flavor sucks but the aroma is nice.\"\n",
    "\n",
    "# Iterar sobres as reviews\n",
    "for review_name, review_text in zip(['Mau', 'Médio', 'Bom'], [review_teste_ma, review_teste_mid, review_teste_boa]):\n",
    "    print(f\"\\n*** Review - {review_name} ***\")\n",
    "\n",
    "    # Iterar pelos classificadores\n",
    "    for clf_name, clf in classificadores:\n",
    "        print(f\"\\n** {clf_name} **\")\n",
    "\n",
    "        # Usar o modelo trainado\n",
    "        pred = clf.predict([review_text])\n",
    "\n",
    "        #Se 1 muito bom se 0 muito mau\n",
    "        sentiment = \"Muito Bom\" if pred[0] == 1 else \"Muito Mau\"\n",
    "\n",
    "        print(f\"The predicted sentiment for the review is: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17add6",
   "metadata": {},
   "source": [
    "Os resultados dos 2 extremos são os esperados mas existe alguma indecisão no que toca a reviews que não declaram com confiança o que sentem. A diferença nos resultados para a análise do meio  entre os classificadores de Regressão Logística e Naive Bayes pode ser atribuída à forma como cada classificador faz previsões com base nas características fornecidas. \n",
    "\n",
    "No caso do classificador Naive Bayes, ele faz previsões usando o teorema de Bayes, assumindo que as características (palavras, neste caso) são condicionalmente independentes dado o rótulo da classe. O Naive Bayes pode ser melhor em capturar a probabilidade de certas combinações de palavras numa análise e não leva em consideração as interações entre as características.\n",
    "\n",
    "\n",
    "Por outro lado, a Regressão Logística considera a combinação linear das características e aplica uma função logística para fazer previsões. Ela pode capturar relações mais complexas entre características e pode ter um desempenho diferente com base na natureza dos dados.\n",
    "\n",
    "Se formos analisar os valores dos coeficientes entre os 2 classificadores conseguimos encontrar uma maior diferença entre os mesmos no classificador de Regressão Logística comparando com o Naive Bayes sendo esta a razão provável de neste ser considerado muito mau e no outro o contrário pois naturalmente \"not good\" vai ter um maior valor comparanando com um cheiro a caramelo.\n",
    "\n",
    "Concluímos que numa review que explique a sua opinião com adjetivos mais fortes conseguimos decifrar com toda a certeza a sua opinião enquanto que com uma mais no meio seja mais duvidoso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1a2bd",
   "metadata": {},
   "source": [
    "Por fim antes de continuarmos para o próximo capitulo vamos analisar quais os valores das reviews têm melhor percentagem de resultados corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdbe7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Categorias de avaliação\n",
    "categorias = [1, 2, 9, 10]\n",
    "\n",
    "# Criar gráfico de barras para cada classificador\n",
    "for nome_clf, clf in classificadores:\n",
    "    # Dicionário para armazenar os resultados\n",
    "    resultados = {'total': {categoria: 0 for categoria in categorias}, 'corretos': {categoria: 0 for categoria in categorias}}\n",
    "\n",
    "    previstos = clf.predict(avaliacoes_filtradas)\n",
    "    \n",
    "    # Avaliar o desempenho do modelo nos dados de teste filtrados\n",
    "    for previsto, real_binario, real_overall in zip(previstos, overall_binarios_filtrados, overall_filtrado):\n",
    "        resultados['total'][real_overall] += 1\n",
    "        if previsto == real_binario:\n",
    "            resultados['corretos'][real_overall] += 1\n",
    "\n",
    "    # Calcular a percentagem de avaliações corretas para cada categoria\n",
    "    percentagens_corretas = [resultados['corretos'][categoria] / resultados['total'][categoria] * 100 if resultados['total'][categoria] != 0 else 0 for categoria in categorias]\n",
    "\n",
    "    # Criar barras com diferentes cores para cada categoria\n",
    "    cores = plt.cm.rainbow(np.linspace(0, 1, len(categorias)))\n",
    "    plt.bar(categorias, percentagens_corretas, color=cores, label=f'{nome_clf}')\n",
    "\n",
    "    # Adicionar rótulos, título e legendas ao gráfico\n",
    "    plt.xlabel('Overall')\n",
    "    plt.ylabel('Percentagem de Avaliações Corretas')\n",
    "    plt.title(f'Desempenho do Classificador \"{nome_clf}\" por Categoria de Avaliação\\n')\n",
    "    plt.ylim(70, 100)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306738e",
   "metadata": {},
   "source": [
    "Podemos observar pelos 2 gráficos acima que um dos valores é claramente mais dificil de fazer a previsão e este é o 2. Isto deve-se ao facto de os reviewers usarem um palavreado mais rico e neutro quando comparando com os outros valores. Vamos ter como exemplo esta review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados do ficheiro pickle\n",
    "dados_teste = pickle.load(open('rateBeer25Ktest.p', 'rb'))\n",
    "\n",
    "# Encontrar uma avaliação com uma pontuação global de 2\n",
    "review_with_score_2 = next((dados_teste[chave] for chave in dados_teste if int(re.search(r'\\d+', dados_teste[chave]['overall']).group()) == 2), None)\n",
    "\n",
    "if review_with_score_2:\n",
    "    print(f\"Avaliação com Pontuação Global de 2:\\n{review_with_score_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767de48d",
   "metadata": {},
   "source": [
    "Como podemos ver este utilizador não utilizou nenhuma das palavras características de uma má review logo fica mais dificil para os classificadores fazerem essa distinção."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540fb95",
   "metadata": {},
   "source": [
    "Os restantes resultados não oferecem muitas introspeções apenas o facto de o classificador Naive Bayes preferir reviews positivas enquanto que a Regressão Logística prefere negativas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8823e",
   "metadata": {},
   "source": [
    "# 4. Classificação  Multi-Classe <a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c25d2a",
   "metadata": {},
   "source": [
    "Prever a pontuação de três aspetos das críticas (smell, taste e overall). Neste ponto, treine e avalie os classificadores com os dados de treino e verifique se as estimativas do desempenho condizem com os resultados obtidos no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b009a9",
   "metadata": {},
   "source": [
    "## 4.1. Treino<a id='section4.1'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "\n",
    "Vai ter um procedimento exatamente igual à fase anterior só que não vamos ter de filtrar as reviews e vamos usar também o smell e taste. Como não temos muito tempo para realizar este trabalho vamos utilizar o mesmo classificador que viemos a utilizar até agora: a Regressão Logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "dados_treino = pickle.load(open('rateBeer75Ktrain.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e rótulos (pontuações do aspecto \"smell\")\n",
    "reviews = [dados_treino[key]['review'] for key in dados_treino]\n",
    "smell_labels = [int(re.search(r'\\d+', dados_treino[key]['smell']).group()) for key in dados_treino]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste para \"smell\"\n",
    "X_treino, X_teste, smell_y_treino, smell_y_teste = train_test_split(\n",
    "    reviews, smell_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Construir um pipeline com vetorização TF-IDF e Logistic Regression (L2 regularization)\n",
    "smell_clf_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        tokenizer=custom_tokenizer,\n",
    "        ngram_range=(1, 4),\n",
    "        min_df=5\n",
    "    )),\n",
    "    ('clf', LogisticRegression(penalty='l2', solver='saga', max_iter=1000, C=1, tol=1e-3))\n",
    "])\n",
    "\n",
    "print(\"Cheiro\\n\")\n",
    "\n",
    "# Treinar o classificador para o aspecto \"smell\"\n",
    "smell_clf_lr.fit(X_treino, smell_y_treino)\n",
    "\n",
    "# Avaliar o classificador nos dados de teste para \"smell\"\n",
    "smell_y_pred_lr = smell_clf_lr.predict(X_teste)\n",
    "\n",
    "# Calcular e imprimir métricas de avaliação para \"smell\"\n",
    "accuracy_lr = accuracy_score(smell_y_teste, smell_y_pred_lr)\n",
    "print(f\"Precisao: {accuracy_lr:.2f}\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(smell_y_teste, smell_y_pred_lr))\n",
    "\n",
    "print(\"\\Matriz de Confusão:\")\n",
    "print(confusion_matrix(smell_y_teste, smell_y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair características (avaliações) e rótulos (pontuações do aspecto \"taste\")\n",
    "taste_labels = [int(re.search(r'\\d+', dados_treino[key]['taste']).group()) for key in dados_treino]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste para \"taste\"\n",
    "X_treino_taste, X_teste_taste, taste_y_treino, taste_y_teste = train_test_split(\n",
    "    reviews, taste_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Construir um pipeline com vetorização TF-IDF e Logistic Regression (L2 regularization)\n",
    "taste_clf_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        tokenizer=custom_tokenizer,\n",
    "        ngram_range=(1, 4),\n",
    "        min_df=5\n",
    "    )),\n",
    "    ('clf', LogisticRegression(penalty='l2', solver='saga', max_iter=1000, C=1, tol=1e-3))\n",
    "])\n",
    "\n",
    "# Treinar o classificador para o aspecto \"taste\"\n",
    "taste_clf_lr.fit(X_treino_taste, taste_y_treino)\n",
    "\n",
    "# Avaliar o classificador nos dados de teste para \"taste\"\n",
    "taste_y_pred_rf = taste_clf_lr.predict(X_teste_taste)\n",
    "\n",
    "print(\"Sabor\\n\")\n",
    "\n",
    "# Calcular e imprimir métricas de avaliação para \"taste\"\n",
    "accuracy_rf_taste = accuracy_score(taste_y_teste, taste_y_pred_rf)\n",
    "print(f\"Precisao: {accuracy_lr:.2f}\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\\n\")\n",
    "print(classification_report(taste_y_teste, taste_y_pred_rf))\n",
    "\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(confusion_matrix(taste_y_teste, taste_y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino = pickle.load(open('rateBeer75Ktrain.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e rótulos (pontuações do aspecto \"smell\")\n",
    "reviews = [dados_treino[key]['review'] for key in dados_treino]\n",
    "\n",
    "# Extrair características (avaliações) e rótulos (pontuações do aspecto \"overall\")\n",
    "overall_labels = [int(re.search(r'\\d+', dados_treino[key]['overall']).group()) for key in dados_treino]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste para \"overall\"\n",
    "X_treino_overall, X_teste_overall, overall_y_treino, overall_y_teste = train_test_split(\n",
    "    reviews, overall_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Construir um pipeline com vetorização TF-IDF e RandomForestClassifier para \"overall\"\n",
    "overall_clf_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        tokenizer=custom_tokenizer,  # Usar o tokenizador personalizado\n",
    "        ngram_range=(1, 4),\n",
    "        min_df=5\n",
    "    )),\n",
    "    ('clf', LogisticRegression(penalty='l2', solver='saga', max_iter=1000, C=1, tol=1e-3))\n",
    "])\n",
    "\n",
    "print(\"Overall\\n\")\n",
    "\n",
    "# Treinar o classificador para o aspecto \"overall\"\n",
    "overall_clf_lr.fit(X_treino_overall, overall_y_treino)\n",
    "\n",
    "# Avaliar o classificador nos dados de teste para \"overall\"\n",
    "overall_y_pred_rf = overall_clf_lr.predict(X_teste_overall)\n",
    "\n",
    "# Calcular e imprimir métricas de avaliação para \"overall\"\n",
    "accuracy_rf_overall = accuracy_score(overall_y_teste, overall_y_pred_rf)\n",
    "print(f\"Precisao: {accuracy_rf_overall:.2f}\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\\n\")\n",
    "print(classification_report(overall_y_teste, overall_y_pred_rf))\n",
    "\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(confusion_matrix(overall_y_teste, overall_y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a90a2d",
   "metadata": {},
   "source": [
    "## 4.2. Teste<a id='section4.2'></a>\n",
    "<hr style=\"height:3px\"/>\n",
    "O processo vai ser, mais uma vez, igual ao anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de teste\n",
    "dados_teste = pickle.load(open('rateBeer25Ktest.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e rótulos para \"smell\", \"taste\" e \"overall\"\n",
    "reviews_teste = [dados_teste[key]['review'] for key in dados_teste]\n",
    "smell_labels = [int(re.search(r'\\d+', dados_teste[key]['smell']).group()) for key in dados_teste]\n",
    "taste_labels = [int(re.search(r'\\d+', dados_teste[key]['taste']).group()) for key in dados_teste]\n",
    "overall_labels = [int(re.search(r'\\d+', dados_teste[key]['overall']).group()) for key in dados_teste]\n",
    "\n",
    "# Predictions\n",
    "smell_y_pred = smell_clf_lr.predict(reviews_teste)\n",
    "taste_y_pred = taste_clf_lr.predict(reviews_teste)\n",
    "overall_y_pred = overall_clf_lr.predict(reviews_teste)\n",
    "\n",
    "# Confusion matrix and classification report for \"smell\"\n",
    "accuracy_smell = accuracy_score(smell_labels, smell_y_pred)\n",
    "print(f\"\\nPrecisao (Smell): {accuracy_smell:.2f}\")\n",
    "conf_matrix_smell = confusion_matrix(smell_labels, smell_y_pred)\n",
    "print(\"\\nMatriz de Confusão (Smell):\\n\")\n",
    "print(conf_matrix_smell)\n",
    "print(\"\\nRelatório de Classificação (Smell):\\n\")\n",
    "print(classification_report(smell_labels, smell_y_pred))\n",
    "\n",
    "# Confusion matrix and classification report for \"taste\"\n",
    "accuracy_taste = accuracy_score(taste_labels, taste_y_pred)\n",
    "print(f\"\\nPrecisao (Taste): {accuracy_taste:.2f}\")\n",
    "conf_matrix_taste = confusion_matrix(taste_labels, taste_y_pred)\n",
    "print(\"\\nMatriz de Confusão (Taste):\\n\")\n",
    "print(conf_matrix_taste)\n",
    "print(\"\\nRelatório de Classificação (Taste):\\n\")\n",
    "print(classification_report(taste_labels, taste_y_pred))\n",
    "\n",
    "# Confusion matrix and classification report for \"overall\"\n",
    "accuracy_overall = accuracy_score(overall_labels, overall_y_pred)\n",
    "print(f\"\\nPrecisao (Overall): {accuracy_overall:.2f}\")\n",
    "conf_matrix_overall = confusion_matrix(overall_labels, overall_y_pred)\n",
    "print(\"\\nMatriz de Confusão (Overall):\\n\")\n",
    "print(conf_matrix_overall)\n",
    "print(\"\\nRelatório de Classificação (Overall):\\n\")\n",
    "print(classification_report(overall_labels, overall_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5f3f6",
   "metadata": {},
   "source": [
    "Os resultados não são bons mas, mais uma vez, era esperado já que nem os docentes conseguiram bons modelos. No entanto, isto não nos impede de tirar conclusões sobre os mesmos. Vamos criar uma função que nos vai permitir que os modelos tentem advinhar qual o score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "\n",
    "    # Cria um dicionario para guardar os valores\n",
    "    predictions = {}\n",
    "\n",
    "    # Predict \"smell\"\n",
    "    smell_prediction = smell_clf_lr.predict([review])[0]\n",
    "    predictions['smell'] = int(re.search(r'\\d+', str(smell_prediction)).group() if smell_prediction else 0)\n",
    "\n",
    "    # Predict \"taste\"\n",
    "    taste_prediction = taste_clf_lr.predict([review])[0]\n",
    "    predictions['taste'] = int(re.search(r'\\d+', str(taste_prediction)).group() if taste_prediction else 0)\n",
    "\n",
    "    # Predict \"overall\"\n",
    "    overall_prediction = overall_clf_lr.predict([review])[0]\n",
    "    predictions['overall'] = int(re.search(r'\\d+', str(overall_prediction)).group() if overall_prediction else 0)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68463989",
   "metadata": {},
   "source": [
    "Criamos também algumas reviews como fizemos anteriormente mas vamos nos focar nos 2 aspetos novos: o cheiro e sabor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"This beer has a bad smelly aroma with hints of citrus but a nice caramel taste.\",\n",
    "    \"This beer has a nice chocolate aroma with hints of citrus but a bad watery flavour.\",\n",
    "    \"This beer has a bad chocolate aroma with hints of cardboard and a bad flavour.\",\n",
    "    \"This beer has a nice chocolate aroma with hints of citrus and great flavour.\"\n",
    "]\n",
    "\n",
    "for i, review in enumerate(reviews, start=1):\n",
    "    predictions = predict(review)\n",
    "    print(f\"\\nPredictions for Review {i}:\\n{predictions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894f56a",
   "metadata": {},
   "source": [
    "Como podemos ver os resultados são péssimos bem podemos estar a elogiar ambas as características, como na review 4, que os resultados não passam de medíocres. Também conseguimos observar que, nas 2 primeiras reviews alternámos entre qual a caracteristica elogiavamos, e não mudava absolutamente nada até fez o contrário pois quando dissémos mal do aroma tivémos o resultado melhor do que quando dissemos que era agradável. Isto é claramente culpa da base de dados pois por muitos testes que fizéssemos quer mudássemos o classificador ou as suas características estes foram os melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83120f6",
   "metadata": {},
   "source": [
    "# 5. PCA <a id='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3b908",
   "metadata": {},
   "source": [
    "Infelizmente não tivemos tempo de acabar este tópico mas fica aqui uma breve introdução. A aplicação de PCA (Principal Component Analysis) pode ter impactos diferentes nas tarefas de classificação binária, especialmente quando se lida com dados textuais. \n",
    "\n",
    "Sem PCA: A precisão pode ser razoavelmente boa, especialmente se os dados já estiverem num formato que permita um bom desempenho do classificador.\n",
    "\n",
    "Com PCA: A redução de dimensionalidade pode ajudar a simplificar o modelo, removendo redundâncias nos dados.\n",
    "Em dados textuais, onde a dimensionalidade pode ser alta, PCA pode ajudar a focar nas principais características, resultando num modelo mais eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados do arquivo pickle\n",
    "dados_treino = pickle.load(open('rateBeer75Ktrain.p', 'rb'))\n",
    "\n",
    "# Extrair características (avaliações) e rótulos (classificações gerais)\n",
    "avaliacoes = [dados_treino[key]['review'] for key in dados_treino]\n",
    "overalls = [int(re.search(r'\\d+', dados_treino[key]['overall']).group()) for key in dados_treino]\n",
    "\n",
    "# Criar rótulos binários para classificação binária (muito bom ou muito mau)\n",
    "overall_binarias = [1 if overall >= 9 else 0 if overall <= 2 else None for overall in overalls]\n",
    "\n",
    "# Remover entradas com None nos rótulos binários\n",
    "dados = list(zip(avaliacoes, overall_binarias))\n",
    "dados = [(avaliacao, overall) for avaliacao, overall in dados if overall is not None]\n",
    "avaliacoes, overall_binarias = zip(*dados)\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(avaliacoes, overall_binarias, test_size=0.2, random_state=42)\n",
    "\n",
    "# Função para realizar a classificação com ou sem PCA\n",
    "def classify_with_pca(X_train, y_train, X_test, y_test, classifier, use_pca=False, n_components=None):\n",
    "    # Definir o classificador\n",
    "    classifier.steps[-1] = ('clf', classifier.steps[-1][1].__class__(max_iter=1000, C=1, tol=1e-3))\n",
    "\n",
    "    # Remover o componente 'svd' se existir\n",
    "    classifier.steps = [step for step in classifier.steps if step[0] != 'svd']\n",
    "    \n",
    "    # Adicionar PCA se necessário\n",
    "    if use_pca:\n",
    "        classifier.steps.insert(-1, ('svd', TruncatedSVD(n_components=n_components)))\n",
    "    \n",
    "    # Treinar o classificador\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar previsões\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Avaliar e retornar a acurácia\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "X_train_array = np.array(X_train)\n",
    "print(f'Dimensão original do conjunto de dados: {X_train_array.shape[0]}')\n",
    "\n",
    "# Classificar sem PCA\n",
    "accuracy_without_pca = classify_with_pca(X_train, y_train, X_test, y_test, regressao_logistica_clf, use_pca=False)\n",
    "print(f'Precisão sem PCA: {accuracy_without_pca:.2f}')\n",
    "\n",
    "# Classificar com PCA (determinar o número ótimo de componentes)\n",
    "best_accuracy = 0\n",
    "best_n_components = 0\n",
    "\n",
    "for n_components in range(1, 100, 10):  \n",
    "    accuracy_with_pca = classify_with_pca(X_train, y_train, X_test, y_test, regressao_logistica_clf, use_pca=True, n_components=n_components)\n",
    "\n",
    "    if accuracy_with_pca > best_accuracy:\n",
    "        best_accuracy = accuracy_with_pca\n",
    "        best_n_components = n_components\n",
    "\n",
    "print(f'Melhor Precisão com PCA ({best_n_components} componentes): {best_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac77e7f",
   "metadata": {},
   "source": [
    "Os resultados indicam que o PCA reduziu para 81 componentes  o que fez com que houvesse uma ligeira redução na precisão do modelo. Podemos tirar algumas conclusões:\n",
    "\n",
    "Sem PCA (Precisão: 0.93): O modelo sem PCA atingiu uma precisão de 93%, o que é bastante bom. Isto sugere que os recursos originais eram informativos e suficientes para obter um bom desempenho.\n",
    "\n",
    "\n",
    "Com PCA (Melhor Precisão com 81 componentes - 0.91): A aplicação de PCA com uma redução para 81 componentes resultou numa precisão ligeiramente inferior (91%). Isso pode indicar que a informação contida nas primeiras 81 componentes não foi tão discriminativa quanto as características originais.\n",
    "\n",
    "\n",
    "A aplicação do PCA é um trade-off entre a simplificação do modelo e a preservação da informação. Em suma, apesar da redução na precisão, uma diminuição de 6718 dados para 71 é uma excelente redução e ajuda imenso na simplificação do modelo oferecendo uma maior rapidez. Isto não é necessário nesta classificação binária devida ao já baixo número de características mas pode ser benéfico noutros casos ou até mesmo na nossa classificação multi-classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132df29a",
   "metadata": {},
   "source": [
    "# 6. Conclusões <a id='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c47ad5",
   "metadata": {},
   "source": [
    "Este trabalho prático deu-nos a possibilidade de consolidar todos os campos lecionadas ao longo da disciplina de Aprendizagem Automática como por exemplo: os diferentes tipos de classificação e os seus diversos classificadores, o modelo Bag of Words ou PCA. Apesar de não termos conseguido os melhores resultados acreditamos que conseguimos atingir todos os requisitos demonstrando o domínio que temos sobre a matéria lecionada. Contudo também acreditamos que se tivéssemos mais tempo ou a base de dados fosse melhor escolhida, conseguíamos facilmente atingir resultados mais satisfatórios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
